{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19adu63iEN8jyOpkgr-HFVb5Q0gOyNvW7","authorship_tag":"ABX9TyNgsZkV5uTq1cg+aAJN+yCX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 深度学习第一次作业"],"metadata":{"id":"7pUI2eigLqap"}},{"cell_type":"markdown","source":["## 作业内容：\n","\n","给定如下方程：\n","\n","$$\n","y = \\log(e^{x} + 5)\n","$$\n","\n","给定$x=5$为初值\n","\n","1. 绘制该公式的计算图，包括每个节点和边。标注每个节点的计算操作(公式形式)\n","2. 对计算图中的每一步进行反向传播，写出每个变量梯度的计算过程与结果\n","3. 使用pytorch的自动求导方法(使用backward)来计算梯度的初始值，验证结果是否准确。\n","4. `(选做)`从底层实现自动求导(numpy和torch皆可)，可参考课件中colab笔记本\n"],"metadata":{"id":"s_eVvEvCPsEI"}},{"cell_type":"markdown","source":["```Mermaid\n","graph LR\n","\tA((A: x))-->C(C: e^A)\n","  C(C: e^A) -.->C1(e^A)\n","\tC(C: e^A) --> E(E: C+D)\n","\tD((D: 5)) --> E(E: C+D)\n","  E(E: C+D) -.->E1(1)\n","\tE(E: C+D) --> F(F: logE)\n","  F(F: logE) -.-> F1(1/E)\n","```"],"metadata":{"id":"4GiuIdKCRLla"}},{"cell_type":"markdown","source":["<img src=\"https://pic.imgdb.cn/item/66dd075fd9c307b7e947e445.png\" alt=\"mermaid-diagram-2024-09-08-100308.png\">"],"metadata":{"id":"de69zR3oax-D"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"h94gDUfcK64-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725760828760,"user_tz":-480,"elapsed":622,"user":{"displayName":"Sean Grow","userId":"05552302781585584661"}},"outputId":"d923f3cc-fb4d-4447-c682-5f2b71330cfa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9674)"]},"metadata":{},"execution_count":34}],"source":["import torch\n","\n","x = torch.tensor(5.0, requires_grad=True)\n","\n","e_x = torch.exp(x)\n","y = torch.log(e_x + 5)\n","\n","y.backward(torch.tensor(1.0))\n","\n","x.grad\n"]},{"cell_type":"code","source":[],"metadata":{"id":"asguTYwHWo2_"},"execution_count":null,"outputs":[]}]}